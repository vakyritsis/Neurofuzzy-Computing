{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.api._v2.keras.layers import Input, Embedding, Dense, TextVectorization, GRU\n",
    "from keras.api._v2.keras.models import Sequential\n",
    "from keras.api._v2.keras.losses import SparseCategoricalCrossentropy\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from load_data import load_l1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>published</th>\n",
       "      <th>published_utc</th>\n",
       "      <th>collection_utc</th>\n",
       "      <th>category_level_1</th>\n",
       "      <th>category_level_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1809</td>\n",
       "      <td>abcnews--2019-10-31--Virginia mom charged with...</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>abcnews</td>\n",
       "      <td>Virginia mom charged with murder in 2-year-old...</td>\n",
       "      <td>The Virginia woman whose 2-year-old son was fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://abcnews.go.com/US/wireStory/virginia-m...</td>\n",
       "      <td>Thu, 31 Oct 2019 16:49:56 -0400</td>\n",
       "      <td>1572554996</td>\n",
       "      <td>1572559512</td>\n",
       "      <td>crime, law and justice</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980</td>\n",
       "      <td>abcnews--2019-11-07--2 escaped murder suspects...</td>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>abcnews</td>\n",
       "      <td>2 escaped murder suspects arrested at US-Mexic...</td>\n",
       "      <td>Authorities are trying to determine if anyone ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://abcnews.go.com/US/wireStory/escaped-mu...</td>\n",
       "      <td>Thu, 07 Nov 2019 00:13:12 -0500</td>\n",
       "      <td>1573103592</td>\n",
       "      <td>1573131986</td>\n",
       "      <td>crime, law and justice</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995</td>\n",
       "      <td>abcnews--2019-11-07--Family turns in escaped b...</td>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>abcnews</td>\n",
       "      <td>Family turns in escaped boy, 13, suspected in ...</td>\n",
       "      <td>A 13-year-old suspect in a double homicide who...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://abcnews.go.com/US/wireStory/family-tur...</td>\n",
       "      <td>Thu, 07 Nov 2019 07:39:54 -0500</td>\n",
       "      <td>1573130394</td>\n",
       "      <td>1573131982</td>\n",
       "      <td>crime, law and justice</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2740</td>\n",
       "      <td>abcnews--2019-12-02--Mother charged with murde...</td>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>abcnews</td>\n",
       "      <td>Mother charged with murder in deaths of 2 youn...</td>\n",
       "      <td>The mother of two young children found hanging...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://abcnews.go.com/US/wireStory/mother-cha...</td>\n",
       "      <td>Mon, 02 Dec 2019 11:30:59 -0500</td>\n",
       "      <td>1575304259</td>\n",
       "      <td>1575308811</td>\n",
       "      <td>crime, law and justice</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7038</td>\n",
       "      <td>ageofautism--2019-04-12--Physician Father and ...</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>ageofautism</td>\n",
       "      <td>Physician, Father and Caretaker of 29 Year Old...</td>\n",
       "      <td>\"One family member said Derek “can be violent ...</td>\n",
       "      <td>Age of Autism</td>\n",
       "      <td>http://feedproxy.google.com/~r/ageofautism/~3/...</td>\n",
       "      <td>2019-04-12 09:00:00+00:00</td>\n",
       "      <td>1555074000</td>\n",
       "      <td>1567543083</td>\n",
       "      <td>crime, law and justice</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id                                                 id        date  \\\n",
       "0     1809  abcnews--2019-10-31--Virginia mom charged with...  2019-10-31   \n",
       "1     1980  abcnews--2019-11-07--2 escaped murder suspects...  2019-11-07   \n",
       "2     1995  abcnews--2019-11-07--Family turns in escaped b...  2019-11-07   \n",
       "3     2740  abcnews--2019-12-02--Mother charged with murde...  2019-12-02   \n",
       "4     7038  ageofautism--2019-04-12--Physician Father and ...  2019-04-12   \n",
       "\n",
       "        source                                              title  \\\n",
       "0      abcnews  Virginia mom charged with murder in 2-year-old...   \n",
       "1      abcnews  2 escaped murder suspects arrested at US-Mexic...   \n",
       "2      abcnews  Family turns in escaped boy, 13, suspected in ...   \n",
       "3      abcnews  Mother charged with murder in deaths of 2 youn...   \n",
       "4  ageofautism  Physician, Father and Caretaker of 29 Year Old...   \n",
       "\n",
       "                                             content         author  \\\n",
       "0  The Virginia woman whose 2-year-old son was fo...            NaN   \n",
       "1  Authorities are trying to determine if anyone ...            NaN   \n",
       "2  A 13-year-old suspect in a double homicide who...            NaN   \n",
       "3  The mother of two young children found hanging...            NaN   \n",
       "4  \"One family member said Derek “can be violent ...  Age of Autism   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://abcnews.go.com/US/wireStory/virginia-m...   \n",
       "1  https://abcnews.go.com/US/wireStory/escaped-mu...   \n",
       "2  https://abcnews.go.com/US/wireStory/family-tur...   \n",
       "3  https://abcnews.go.com/US/wireStory/mother-cha...   \n",
       "4  http://feedproxy.google.com/~r/ageofautism/~3/...   \n",
       "\n",
       "                         published  published_utc  collection_utc  \\\n",
       "0  Thu, 31 Oct 2019 16:49:56 -0400     1572554996      1572559512   \n",
       "1  Thu, 07 Nov 2019 00:13:12 -0500     1573103592      1573131986   \n",
       "2  Thu, 07 Nov 2019 07:39:54 -0500     1573130394      1573131982   \n",
       "3  Mon, 02 Dec 2019 11:30:59 -0500     1575304259      1575308811   \n",
       "4        2019-04-12 09:00:00+00:00     1555074000      1567543083   \n",
       "\n",
       "         category_level_1 category_level_2  \n",
       "0  crime, law and justice            crime  \n",
       "1  crime, law and justice            crime  \n",
       "2  crime, law and justice            crime  \n",
       "3  crime, law and justice            crime  \n",
       "4  crime, law and justice            crime  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('news-classification.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val, y_train, y_test, y_val = load_l1_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONLY RUN TO DOWNLOAD GLOVE EMBENDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
    "# !unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standarization(input_data):\n",
    "\n",
    "        text = tf.strings.lower(input_data)\n",
    "        text = tf.strings.regex_replace(text, r'\\d+|http\\S+', '')\n",
    "        text = tf.strings.regex_replace(text, '[^a-zA-Z,\\d]', ' ')\n",
    "        text = tf.strings.regex_replace(text, r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b', ' ')\n",
    "        text = tf.strings.regex_replace(text, '[/(){}\\[\\]\\|@,;]', ' ')\n",
    "        text = tf.strings.regex_replace(text, ' +', ' ')\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 8000\n",
    "encoder = TextVectorization(standardize=custom_standarization, max_tokens=VOCAB_SIZE, output_sequence_length=500)\n",
    "encoder.adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = encoder.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = \"glove.6B.100d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 7948 words (52 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    trainable=True,\n",
    ")\n",
    "embedding_layer.build((1,))\n",
    "embedding_layer.set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfClasses = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU MODEL FOR LEVEL 1 CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, None, 100)         800200    \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 1792)             5365248   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 17)                30481     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,195,929\n",
      "Trainable params: 6,195,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(None,), dtype=\"int32\"),\n",
    "    embedding_layer,\n",
    "    tf.keras.layers.Bidirectional(GRU(896, dropout=0.35)),\n",
    "    Dense(numberOfClasses, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = encoder(np.array([[s] for s in x_train])).numpy()\n",
    "x_val = encoder(np.array([[s] for s in x_val])).numpy()\n",
    "x_test = encoder(np.array([[s] for s in x_test])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=SparseCategoricalCrossentropy(),\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "239/239 [==============================] - 67s 267ms/step - loss: 1.6355 - accuracy: 0.4960 - val_loss: 1.0074 - val_accuracy: 0.6960\n",
      "Epoch 2/7\n",
      "239/239 [==============================] - 56s 236ms/step - loss: 0.8368 - accuracy: 0.7405 - val_loss: 0.7332 - val_accuracy: 0.7845\n",
      "Epoch 3/7\n",
      "239/239 [==============================] - 55s 231ms/step - loss: 0.5768 - accuracy: 0.8198 - val_loss: 0.6221 - val_accuracy: 0.7961\n",
      "Epoch 4/7\n",
      "239/239 [==============================] - 59s 246ms/step - loss: 0.4198 - accuracy: 0.8614 - val_loss: 0.5692 - val_accuracy: 0.8248\n",
      "Epoch 5/7\n",
      "239/239 [==============================] - 58s 242ms/step - loss: 0.3824 - accuracy: 0.8768 - val_loss: 0.6139 - val_accuracy: 0.8315\n",
      "Epoch 6/7\n",
      "239/239 [==============================] - 56s 234ms/step - loss: 0.3468 - accuracy: 0.8890 - val_loss: 0.5798 - val_accuracy: 0.8321\n",
      "Epoch 7/7\n",
      "239/239 [==============================] - 53s 223ms/step - loss: 0.2410 - accuracy: 0.9194 - val_loss: 0.5758 - val_accuracy: 0.8486\n"
     ]
    }
   ],
   "source": [
    "glove_history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=7,\n",
    "    validation_steps=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 7s 133ms/step - loss: 0.6194 - accuracy: 0.8437\n",
      "Loss:  0.6194208264350891\n",
      "Accuracy:  0.8437118530273438\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = glove_history.history\n",
    "history_dict.keys()\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU LEVEL 1 TUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN THIS CELL\n",
    "# THIS CODE WAS USED FOR HYPERPARAMETER TUNNING\n",
    "import keras_tuner as kt\n",
    "def model_builder(hp): \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(None,), dtype=\"int32\"))\n",
    "    model.add(embedding_layer)\n",
    "    \n",
    "    hp_units = hp.Int('units', min_value=64, max_value=1024, step=32)\n",
    "\n",
    "    model.add(tf.keras.layers.Bidirectional(GRU(units=hp_units, dropout=0.2)))\n",
    "    model.add(Dense(numberOfClasses, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=SparseCategoricalCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=15,\n",
    "                     factor=3,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train, epochs=50, validation_data=(x_val, y_val), callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
