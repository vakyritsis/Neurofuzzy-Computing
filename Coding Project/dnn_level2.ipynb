{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.api._v2.keras.layers import Input, Embedding, SimpleRNN, Dense, TextVectorization, GRU, Dropout\n",
    "from keras.api._v2.keras.models import Sequential\n",
    "from keras.api._v2.keras.losses import SparseCategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from load_data import load_l2_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>published</th>\n",
       "      <th>published_utc</th>\n",
       "      <th>collection_utc</th>\n",
       "      <th>category_level_1</th>\n",
       "      <th>category_level_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1809</td>\n",
       "      <td>abcnews--2019-10-31--Virginia mom charged with...</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>abcnews</td>\n",
       "      <td>Virginia mom charged with murder in 2-year-old...</td>\n",
       "      <td>The Virginia woman whose 2-year-old son was fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://abcnews.go.com/US/wireStory/virginia-m...</td>\n",
       "      <td>Thu, 31 Oct 2019 16:49:56 -0400</td>\n",
       "      <td>1572554996</td>\n",
       "      <td>1572559512</td>\n",
       "      <td>crime, law and justice</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980</td>\n",
       "      <td>abcnews--2019-11-07--2 escaped murder suspects...</td>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>abcnews</td>\n",
       "      <td>2 escaped murder suspects arrested at US-Mexic...</td>\n",
       "      <td>Authorities are trying to determine if anyone ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://abcnews.go.com/US/wireStory/escaped-mu...</td>\n",
       "      <td>Thu, 07 Nov 2019 00:13:12 -0500</td>\n",
       "      <td>1573103592</td>\n",
       "      <td>1573131986</td>\n",
       "      <td>crime, law and justice</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995</td>\n",
       "      <td>abcnews--2019-11-07--Family turns in escaped b...</td>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>abcnews</td>\n",
       "      <td>Family turns in escaped boy, 13, suspected in ...</td>\n",
       "      <td>A 13-year-old suspect in a double homicide who...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://abcnews.go.com/US/wireStory/family-tur...</td>\n",
       "      <td>Thu, 07 Nov 2019 07:39:54 -0500</td>\n",
       "      <td>1573130394</td>\n",
       "      <td>1573131982</td>\n",
       "      <td>crime, law and justice</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2740</td>\n",
       "      <td>abcnews--2019-12-02--Mother charged with murde...</td>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>abcnews</td>\n",
       "      <td>Mother charged with murder in deaths of 2 youn...</td>\n",
       "      <td>The mother of two young children found hanging...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://abcnews.go.com/US/wireStory/mother-cha...</td>\n",
       "      <td>Mon, 02 Dec 2019 11:30:59 -0500</td>\n",
       "      <td>1575304259</td>\n",
       "      <td>1575308811</td>\n",
       "      <td>crime, law and justice</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7038</td>\n",
       "      <td>ageofautism--2019-04-12--Physician Father and ...</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>ageofautism</td>\n",
       "      <td>Physician, Father and Caretaker of 29 Year Old...</td>\n",
       "      <td>\"One family member said Derek “can be violent ...</td>\n",
       "      <td>Age of Autism</td>\n",
       "      <td>http://feedproxy.google.com/~r/ageofautism/~3/...</td>\n",
       "      <td>2019-04-12 09:00:00+00:00</td>\n",
       "      <td>1555074000</td>\n",
       "      <td>1567543083</td>\n",
       "      <td>crime, law and justice</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id                                                 id        date  \\\n",
       "0     1809  abcnews--2019-10-31--Virginia mom charged with...  2019-10-31   \n",
       "1     1980  abcnews--2019-11-07--2 escaped murder suspects...  2019-11-07   \n",
       "2     1995  abcnews--2019-11-07--Family turns in escaped b...  2019-11-07   \n",
       "3     2740  abcnews--2019-12-02--Mother charged with murde...  2019-12-02   \n",
       "4     7038  ageofautism--2019-04-12--Physician Father and ...  2019-04-12   \n",
       "\n",
       "        source                                              title  \\\n",
       "0      abcnews  Virginia mom charged with murder in 2-year-old...   \n",
       "1      abcnews  2 escaped murder suspects arrested at US-Mexic...   \n",
       "2      abcnews  Family turns in escaped boy, 13, suspected in ...   \n",
       "3      abcnews  Mother charged with murder in deaths of 2 youn...   \n",
       "4  ageofautism  Physician, Father and Caretaker of 29 Year Old...   \n",
       "\n",
       "                                             content         author  \\\n",
       "0  The Virginia woman whose 2-year-old son was fo...            NaN   \n",
       "1  Authorities are trying to determine if anyone ...            NaN   \n",
       "2  A 13-year-old suspect in a double homicide who...            NaN   \n",
       "3  The mother of two young children found hanging...            NaN   \n",
       "4  \"One family member said Derek “can be violent ...  Age of Autism   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://abcnews.go.com/US/wireStory/virginia-m...   \n",
       "1  https://abcnews.go.com/US/wireStory/escaped-mu...   \n",
       "2  https://abcnews.go.com/US/wireStory/family-tur...   \n",
       "3  https://abcnews.go.com/US/wireStory/mother-cha...   \n",
       "4  http://feedproxy.google.com/~r/ageofautism/~3/...   \n",
       "\n",
       "                         published  published_utc  collection_utc  \\\n",
       "0  Thu, 31 Oct 2019 16:49:56 -0400     1572554996      1572559512   \n",
       "1  Thu, 07 Nov 2019 00:13:12 -0500     1573103592      1573131986   \n",
       "2  Thu, 07 Nov 2019 07:39:54 -0500     1573130394      1573131982   \n",
       "3  Mon, 02 Dec 2019 11:30:59 -0500     1575304259      1575308811   \n",
       "4        2019-04-12 09:00:00+00:00     1555074000      1567543083   \n",
       "\n",
       "         category_level_1 category_level_2  \n",
       "0  crime, law and justice            crime  \n",
       "1  crime, law and justice            crime  \n",
       "2  crime, law and justice            crime  \n",
       "3  crime, law and justice            crime  \n",
       "4  crime, law and justice            crime  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('news-classification.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "default_stemmer = PorterStemmer()\n",
    "default_stopwords = stopwords.words('english')\n",
    "default_stopwords = default_stopwords + ['said', 'would','even','according','could','year',\n",
    "                                         'years','also','new','people','old,''one','two','time',\n",
    "                                         'first','last','say','make','best','get','three','make',\n",
    "                                         'year old','told','made','like','take','many','set','number',\n",
    "                                         'month','week','well','back']\n",
    "shortword = re.compile(r'\\W*\\b\\w{1,4}\\b\\d')\n",
    "BAD_SYMBOLS_RE = re.compile(\"[^a-zA-Z,\\\\d]\")\n",
    "REPLACE_IP_ADDRESS = re.compile(r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b')\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\\\[\\\\]\\\\|@,;]')\n",
    "def clean_text(text, ):\n",
    "\n",
    "    def tokenize_text(text):\n",
    "        return [w for s in sent_tokenize(text) for w in word_tokenize(s) if len(w)>=3]\n",
    "\n",
    "    def preprocessing_text(text):\n",
    "        text = text.lower()\n",
    "        text=text.replace('\\n',' ').replace('\\xa0',' ').replace('-',' ').replace('ó','o').replace('ğ','g').replace('á','a').replace(\"'\",\" \")\n",
    "        text=re.sub(r'\\d+','', text)\n",
    "        text=re.sub(r'http\\S+', '', text)\n",
    "        text=BAD_SYMBOLS_RE.sub(' ', text)\n",
    "        text=REPLACE_IP_ADDRESS.sub('', text)\n",
    "        text=REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "        text=' '.join(word for word in text.split() if len(word)>3)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def remove_special_characters(text, characters=string.punctuation.replace('-', '')):\n",
    "        tokens = tokenize_text(text)\n",
    "        pattern = re.compile('[{}]'.format(re.escape(characters + '0123456789')))\n",
    "        return ' '.join(filter(None, [pattern.sub('', t) for t in tokens]))\n",
    "\n",
    "    def stem_text(text, stemmer=default_stemmer):\n",
    "        tokens = tokenize_text(text)\n",
    "        return ' '.join([stemmer.stem(t) for t in tokens])\n",
    "\n",
    "    def lemm_text(text, lemm=WordNetLemmatizer()):\n",
    "        tokens = tokenize_text(text)\n",
    "        return ' '.join([lemm.lemmatize(t) for t in tokens])\n",
    "\n",
    "    def remove_stopwords(text, stop_words=default_stopwords):\n",
    "        tokens = [w for w in tokenize_text(text) if w not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    text = text.strip(' ') # strip whitespaces\n",
    "    text = text.lower() # lowercase\n",
    "    text = preprocessing_text(text)\n",
    "    text = remove_special_characters(text) # remove punctuation and symbols\n",
    "    text = lemm_text(text) # lemmatizer\n",
    "    text = remove_stopwords(text) # remove stopwords\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['category_level_1'] = label_encoder.fit_transform(df['category_level_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_features = []\n",
    "l2_target = []\n",
    "# Iterate over unique values in 'category_level_1'\n",
    "for category_level_1_value in range(0, 17):\n",
    "    # Filter DataFrame based on 'category_level_1'\n",
    "    subset_df = df[df['category_level_1'] == category_level_1_value]\n",
    "\n",
    "    # Create a new DataFrame with selected columns\n",
    "    subset_features = subset_df[['source', 'title', 'content']]\n",
    "    subset_features = subset_features.apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
    "    subset_features = subset_features.apply(clean_text)\n",
    "    \n",
    "    subset_target = subset_df['category_level_2']\n",
    "    # Append the new DataFrame to the list\n",
    "    l2_features.append(subset_features)\n",
    "    l2_target.append(subset_target)\n",
    "\n",
    "# Now, list_of_dataframes contains DataFrames for each 'category_level_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_x_train, l2_x_test, l2_x_val, l2_y_train, l2_y_test, l2_y_val = load_l2_data(l2_features, l2_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_dnn(x_train, x_val, x_test, nClasses):\n",
    "    max_features = 20000\n",
    "    vectorizer_x = TfidfVectorizer(max_features=max_features, ngram_range=(1,2))\n",
    "\n",
    "    x_train = vectorizer_x.fit_transform(x_train).toarray()\n",
    "    x_val = vectorizer_x.transform(x_val).toarray()\n",
    "    x_test = vectorizer_x.transform(x_test).toarray()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(400, input_dim=max_features))  # Specify input_dim here\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=SparseCategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model, x_train, x_val, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  0\n",
      "Model:  1\n",
      "Model:  2\n",
      "Model:  3\n",
      "Model:  4\n",
      "Model:  5\n",
      "Model:  6\n",
      "Model:  7\n",
      "Model:  8\n",
      "Model:  9\n",
      "Model:  10\n",
      "Model:  11\n",
      "Model:  12\n",
      "Model:  13\n",
      "Model:  14\n",
      "Model:  15\n",
      "Model:  16\n"
     ]
    }
   ],
   "source": [
    "l2_dnn_models = []\n",
    "for i in range(0, 17):\n",
    "    l2_dnn_models.append([])\n",
    "\n",
    "for i in range(0, 17):\n",
    "    print(\"Model: \",i)\n",
    "    with tf.device(\"CPU\"):\n",
    "        l2_dnn_models[i], l2_x_train[i], l2_x_val[i], l2_x_test[i] = build_model_dnn(l2_x_train[i], l2_x_val[i], l2_x_test[i], len(np.unique(l2_target[i])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0060 - accuracy: 0.5905 - val_loss: 0.8537 - val_accuracy: 0.7111\n",
      "Epoch 2/6\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.5615 - accuracy: 0.9857 - val_loss: 0.6365 - val_accuracy: 0.8222\n",
      "Model:  1\n",
      "Epoch 1/6\n",
      "35/35 [==============================] - 1s 14ms/step - loss: 1.7128 - accuracy: 0.7357 - val_loss: 1.3235 - val_accuracy: 0.8667\n",
      "Epoch 2/6\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.6850 - accuracy: 0.9518 - val_loss: 0.7239 - val_accuracy: 0.8583\n",
      "Model:  2\n",
      "Epoch 1/6\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 1.5098 - accuracy: 0.5057 - val_loss: 1.3427 - val_accuracy: 0.6533\n",
      "Epoch 2/6\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.9659 - accuracy: 0.9371 - val_loss: 1.0431 - val_accuracy: 0.7200\n",
      "Model:  3\n",
      "Epoch 1/6\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 1.5341 - accuracy: 0.4286 - val_loss: 1.3738 - val_accuracy: 0.6533\n",
      "Epoch 2/6\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.9905 - accuracy: 0.9314 - val_loss: 1.1206 - val_accuracy: 0.6400\n",
      "Model:  4\n",
      "Epoch 1/6\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1.2982 - accuracy: 0.6143 - val_loss: 1.2013 - val_accuracy: 0.7000\n",
      "Epoch 2/6\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.7937 - accuracy: 0.9786 - val_loss: 1.0405 - val_accuracy: 0.6167\n",
      "Model:  5\n",
      "Epoch 1/6\n",
      "27/27 [==============================] - 1s 14ms/step - loss: 1.7262 - accuracy: 0.3726 - val_loss: 1.6485 - val_accuracy: 0.4457\n",
      "Epoch 2/6\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.1903 - accuracy: 0.9057 - val_loss: 1.4866 - val_accuracy: 0.5217\n",
      "Model:  6\n",
      "Epoch 1/6\n",
      "27/27 [==============================] - 1s 14ms/step - loss: 1.6719 - accuracy: 0.5262 - val_loss: 1.4756 - val_accuracy: 0.6889\n",
      "Epoch 2/6\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.9991 - accuracy: 0.9238 - val_loss: 1.0762 - val_accuracy: 0.7667\n",
      "Model:  7\n",
      "Epoch 1/6\n",
      "31/31 [==============================] - 1s 14ms/step - loss: 1.7678 - accuracy: 0.5327 - val_loss: 1.5003 - val_accuracy: 0.7048\n",
      "Epoch 2/6\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.9965 - accuracy: 0.9429 - val_loss: 1.1003 - val_accuracy: 0.7429\n",
      "Model:  8\n",
      "Epoch 1/6\n",
      "27/27 [==============================] - 1s 14ms/step - loss: 1.6641 - accuracy: 0.5976 - val_loss: 1.4945 - val_accuracy: 0.7333\n",
      "Epoch 2/6\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.9911 - accuracy: 0.9690 - val_loss: 1.1294 - val_accuracy: 0.7889\n",
      "Model:  9\n",
      "Epoch 1/6\n",
      "31/31 [==============================] - 1s 14ms/step - loss: 1.8159 - accuracy: 0.4411 - val_loss: 1.6185 - val_accuracy: 0.5189\n",
      "Epoch 2/6\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 1.1719 - accuracy: 0.7825 - val_loss: 1.2804 - val_accuracy: 0.5849\n",
      "Model:  10\n",
      "Epoch 1/6\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.9682 - accuracy: 0.7381 - val_loss: 0.7394 - val_accuracy: 0.9556\n",
      "Epoch 2/6\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4559 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.9778\n",
      "Model:  11\n",
      "Epoch 1/6\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 2.0097 - accuracy: 0.4683 - val_loss: 1.7021 - val_accuracy: 0.7185\n",
      "Epoch 2/6\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1734 - accuracy: 0.9349 - val_loss: 1.2259 - val_accuracy: 0.7481\n",
      "Model:  12\n",
      "Epoch 1/6\n",
      "35/35 [==============================] - 1s 13ms/step - loss: 1.9725 - accuracy: 0.3304 - val_loss: 1.8242 - val_accuracy: 0.5333\n",
      "Epoch 2/6\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.3383 - accuracy: 0.9000 - val_loss: 1.5126 - val_accuracy: 0.6083\n",
      "Model:  13\n",
      "Epoch 1/6\n",
      "35/35 [==============================] - 1s 13ms/step - loss: 1.9452 - accuracy: 0.4286 - val_loss: 1.7450 - val_accuracy: 0.6750\n",
      "Epoch 2/6\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 1.2240 - accuracy: 0.9036 - val_loss: 1.3533 - val_accuracy: 0.6833\n",
      "Model:  14\n",
      "Epoch 1/6\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 2.1248 - accuracy: 0.5857 - val_loss: 1.7459 - val_accuracy: 0.7576\n",
      "Epoch 2/6\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 1.0287 - accuracy: 0.9805 - val_loss: 0.9949 - val_accuracy: 0.8485\n",
      "Model:  15\n",
      "Epoch 1/6\n",
      "40/40 [==============================] - 1s 14ms/step - loss: 1.8139 - accuracy: 0.5410 - val_loss: 1.4608 - val_accuracy: 0.7153\n",
      "Epoch 2/6\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8933 - accuracy: 0.9353 - val_loss: 1.0040 - val_accuracy: 0.7737\n",
      "Model:  16\n",
      "Epoch 1/6\n",
      "18/18 [==============================] - 1s 18ms/step - loss: 1.2424 - accuracy: 0.4964 - val_loss: 1.0619 - val_accuracy: 0.6667\n",
      "Epoch 2/6\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.6731 - accuracy: 0.9250 - val_loss: 0.8221 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(patience=1)\n",
    "\n",
    "for i in range(0, 17):\n",
    "    print(\"Model: \", i)\n",
    "    with tf.device(\"CPU\"):\n",
    "        l2_dnn_models[i].fit(\n",
    "        l2_x_train[i], l2_y_train[i],\n",
    "        validation_data=(l2_x_val[i], l2_y_val[i]),\n",
    "        epochs=6,\n",
    "        batch_size=16,\n",
    "        callbacks=[callback]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5862 - accuracy: 0.8444\n",
      "Model:  0\n",
      "Loss:  0.5862075686454773\n",
      "Accuracy:  0.8444444537162781\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.6520 - accuracy: 0.8833\n",
      "Model:  1\n",
      "Loss:  0.6519753932952881\n",
      "Accuracy:  0.8833333253860474\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0738 - accuracy: 0.7067\n",
      "Model:  2\n",
      "Loss:  1.0737907886505127\n",
      "Accuracy:  0.7066666483879089\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.2212 - accuracy: 0.6667\n",
      "Model:  3\n",
      "Loss:  1.2212083339691162\n",
      "Accuracy:  0.6666666865348816\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0944 - accuracy: 0.7333\n",
      "Model:  4\n",
      "Loss:  1.094390630722046\n",
      "Accuracy:  0.7333333492279053\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.4225 - accuracy: 0.5604\n",
      "Model:  5\n",
      "Loss:  1.4224733114242554\n",
      "Accuracy:  0.5604395866394043\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.9995 - accuracy: 0.8333\n",
      "Model:  6\n",
      "Loss:  0.9994742274284363\n",
      "Accuracy:  0.8333333134651184\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1078 - accuracy: 0.7714\n",
      "Model:  7\n",
      "Loss:  1.107757568359375\n",
      "Accuracy:  0.7714285850524902\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.0327 - accuracy: 0.7778\n",
      "Model:  8\n",
      "Loss:  1.0327329635620117\n",
      "Accuracy:  0.7777777910232544\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1830 - accuracy: 0.6762\n",
      "Model:  9\n",
      "Loss:  1.1829743385314941\n",
      "Accuracy:  0.6761904954910278\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4987 - accuracy: 1.0000\n",
      "Model:  10\n",
      "Loss:  0.49868836998939514\n",
      "Accuracy:  1.0\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3114 - accuracy: 0.6519\n",
      "Model:  11\n",
      "Loss:  1.3113579750061035\n",
      "Accuracy:  0.6518518328666687\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.5496 - accuracy: 0.6167\n",
      "Model:  12\n",
      "Loss:  1.5496000051498413\n",
      "Accuracy:  0.6166666746139526\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.4070 - accuracy: 0.6250\n",
      "Model:  13\n",
      "Loss:  1.407043218612671\n",
      "Accuracy:  0.625\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9936 - accuracy: 0.8667\n",
      "Model:  14\n",
      "Loss:  0.9935981631278992\n",
      "Accuracy:  0.8666666746139526\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.9692 - accuracy: 0.7868\n",
      "Model:  15\n",
      "Loss:  0.9691557288169861\n",
      "Accuracy:  0.7867646813392639\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8318 - accuracy: 0.6667\n",
      "Model:  16\n",
      "Loss:  0.8317661881446838\n",
      "Accuracy:  0.6666666865348816\n",
      "[0.8444444537162781, 0.8833333253860474, 0.7066666483879089, 0.6666666865348816, 0.7333333492279053, 0.5604395866394043, 0.8333333134651184, 0.7714285850524902, 0.7777777910232544, 0.6761904954910278, 1.0, 0.6518518328666687, 0.6166666746139526, 0.625, 0.8666666746139526, 0.7867646813392639, 0.6666666865348816]\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for i in range(0, 17):\n",
    "    loss, accuracy = l2_dnn_models[i].evaluate(l2_x_test[i], l2_y_test[i])\n",
    "    print(\"Model: \", i)\n",
    "    print(\"Loss: \", loss)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
